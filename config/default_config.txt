[image modality 1]
path_to_search = ./example_volumes/monomodal_parcellation
filename_contains = T1
filename_not_contains =

[label modality 1]
path_to_search = ./example_volumes/monomodal_parcellation
filename_contains = Label
filename_not_contains =

[settings]
cuda_devices = ""
model_dir = ./models/model_monomodal_toy
net_name = toynet
activation_function = prelu

# preprocessing threads parameters
queue_length = 20
num_threads = 2

# network parameters (controlling memory consumption)
spatial_rank = 3
batch_size = 4
image_size = 32
label_size = 32
w_map_size = 32
num_classes = 160

# affected by network's receptive field
volume_padding_size = 21
#histogram normalisation
histogram_ref_file = ./example_volumes/monomodal_parcellation/standardisation_models.txt
multimod_mask_type = and
norm_type = percentile
cutoff_min = 0.01
cutoff_max = 0.99
mask_type = otsu_plus

# volume level preprocessing
reorientation = True
resampling = True
normalisation = True
whitening = True
image_interp_order = 3
label_interp_order = 0
w_map_interp_order = 3

# ** training only ** system parameters
num_gpus = 1
sample_per_volume = 32

# training augmentation
rotation = True
min_angle = -10.0
max_angle = 10.0
spatial_scaling = True
min_percentage = -10.0
max_percentage = 10.0
window_sampling = uniform
min_numb_labels = 2
min_sampling_ratio = 0.000001

# ** training only ** gradient descent and loss parameters
lr = 0.01
decay = 0
loss_type = Dice
reg_type = L2
starting_iter = 0
save_every_n = 100
max_iter = 10

# ** inference only ** system parameters
border = 5
pred_iter = 10
save_seg_dir = ./output/toy

output_interp_order = 0
output_prob = False
